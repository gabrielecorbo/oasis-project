points( g$fitted.values[ watchout_ids_lev ], watchout_points_lev, col = 'red', pch = 16 )
lev [ lev >  2 * 5 / 50 ]
sum( lev [ lev >  2 * 5 / 50 ] )
#Fit the model without leverages.
gl = lm( sr ~ pop15 + pop75 + dpi + ddpi, savings, subset = ( lev < 0.2 ) )
summary( gl )
#summary( g )
# Moreover, investigate the relative variation of hat(beta) due to these influential points.
abs( ( g$coefficients - gl$coefficients ) / g$coefficients )
# The leverages affect the estimates heavily (there is a variation of 22\% at least).
# We can also visualize the position of leverages for each covariate couple.
colors = rep( 'black', nrow( savings ) )
colors[ watchout_ids_lev ] = c('red', 'blue', 'green', 'orange')
pairs( savings[ , c( 'sr', 'pop15', 'pop75', 'dpi', 'ddpi' ) ],
pch = 16, col = colors, cex = 1 + 0.5 * as.numeric( colors != 'black' ))
### b. Standardized Residuals
#Plot the residuals of the complete model.
# Residui non standardizzati (e non studentizzati)
plot( g$res, ylab = "Residuals", main = "Plot of residuals" )
sort( g$res )
sort( g$res ) [ c( 1, 50 ) ]  ## per vedere il primo e l'ultimo residuo
countries = row.names( savings )
gs = summary(g)
res_std = g$res/gs$sigma
watchout_ids_rstd = which( abs( res_std ) > 2 )
watchout_rstd = res_std[ watchout_ids_rstd ]
watchout_rstd
# Residui standardizzati
plot( g$fitted.values, res_std, ylab = "Standardized Residuals", main = "Standardized Residuals" )
abline( h = c(-2,2), lty = 2, col = 'orange' )
points( g$fitted.values[watchout_ids_rstd],
res_std[watchout_ids_rstd], col = 'red', pch = 16 )
points( g$fitted.values[watchout_ids_lev],
res_std[watchout_ids_lev], col = 'orange', pch = 16 )
legend('topright', col = c('red','orange'),
c('Standardized Residuals', 'Leverages'), pch = rep( 16, 2 ), bty = 'n' )
### c. Studentized Residuals
# #__Rule of thumb__ A point i is influential if |r_i^{stud}|>2
#Compute the Studentized Residuals, highlighting the influential points.
gs = summary( g )
gs$sigma
# manually
stud = g$residuals / ( gs$sigma * sqrt( 1 - lev ) )
# 'rstandard' gives studentized residuals automaically
stud = rstandard( g )
watchout_ids_stud = which( abs( stud ) > 2 )
watchout_stud = stud[ watchout_ids_stud ]
watchout_stud
plot( g$fitted.values, stud, ylab = "Studentized Residuals", main = "Studentized Residuals", pch = 16 )
points( g$fitted.values[watchout_ids_stud],
stud[watchout_ids_stud], col = 'pink', pch = 16 )
points( g$fitted.values[watchout_ids_lev],
stud[watchout_ids_lev], col = 'orange', pch = 16 )
abline( h = c(-2,2), lty = 2, col = 'orange' )
legend('topright', col = c('pink','orange'),
c('Studentized Residual', 'Leverages'), pch = rep( 16, 3 ), bty = 'n' )
# Secondly, we fit the complete linear model (Lab 1) and look at the summary of the estimated coefficients.
g = lm( sr ~ pop15 + pop75 + dpi + ddpi, data = savings )
#g = lm( sr ~ ., savings )
summary( g )
gs = summary( g )
X = model.matrix( g )
X
lev = hat( X )
lev
# or
lev = hatvalues( g )
lev
#Alternatively, we can compute H manually and then exctract its diagonal elements:
#manually
H = X %*% solve( t( X ) %*% X ) %*% t( X )
lev = diag( H )
sum(lev) # verifica: sum_i hat( x )_i = p
# __Rule of thumb:__ Given a point h_ii diagonal element of H, the i-th observation is a leverage if:
#  h_ii > 2*p/n
p = g$rank # p = 5
n = dim(savings)[1] # n = 50
plot( g$fitted.values, lev, ylab = "Leverages", main = "Plot of Leverages",
pch = 16, col = 'black' )
abline( h = 2 * p/n, lty = 2, col = 'red' )
watchout_points_lev = lev[ which( lev > 2 * p/n  ) ]
watchout_ids_lev = seq_along( lev )[ which( lev > 2 * p/n ) ]
points( g$fitted.values[ watchout_ids_lev ], watchout_points_lev, col = 'red', pch = 16 )
lev [ lev >  2 * 5 / 50 ]
sum( lev [ lev >  2 * 5 / 50 ] )
#Fit the model without leverages.
gl = lm( sr ~ pop15 + pop75 + dpi + ddpi, savings, subset = ( lev < 0.2 ) )
summary( gl )
#summary( g )
# Moreover, investigate the relative variation of hat(beta) due to these influential points.
abs( ( g$coefficients - gl$coefficients ) / g$coefficients )
# The leverages affect the estimates heavily (there is a variation of 22\% at least).
# We can also visualize the position of leverages for each covariate couple.
colors = rep( 'black', nrow( savings ) )
colors[ watchout_ids_lev ] = c('red', 'blue', 'green', 'orange')
pairs( savings[ , c( 'sr', 'pop15', 'pop75', 'dpi', 'ddpi' ) ],
pch = 16, col = colors, cex = 1 + 0.5 * as.numeric( colors != 'black' ))
### b. Standardized Residuals
#Plot the residuals of the complete model.
# Residui non standardizzati (e non studentizzati)
plot( g$res, ylab = "Residuals", main = "Plot of residuals" )
sort( g$res )
sort( g$res ) [ c( 1, 50 ) ]  ## per vedere il primo e l'ultimo residuo
countries = row.names( savings )
gs = summary(g)
res_std = g$res/gs$sigma
watchout_ids_rstd = which( abs( res_std ) > 2 )
watchout_rstd = res_std[ watchout_ids_rstd ]
watchout_rstd
# Residui standardizzati
plot( g$fitted.values, res_std, ylab = "Standardized Residuals", main = "Standardized Residuals" )
abline( h = c(-2,2), lty = 2, col = 'orange' )
points( g$fitted.values[watchout_ids_rstd],
res_std[watchout_ids_rstd], col = 'red', pch = 16 )
points( g$fitted.values[watchout_ids_lev],
res_std[watchout_ids_lev], col = 'orange', pch = 16 )
legend('topright', col = c('red','orange'),
c('Standardized Residuals', 'Leverages'), pch = rep( 16, 2 ), bty = 'n' )
### c. Studentized Residuals
# #__Rule of thumb__ A point i is influential if |r_i^{stud}|>2
#Compute the Studentized Residuals, highlighting the influential points.
gs = summary( g )
gs$sigma
# manually
stud = g$residuals / ( gs$sigma * sqrt( 1 - lev ) )
# 'rstandard' gives studentized residuals automaically
stud = rstandard( g )
watchout_ids_stud = which( abs( stud ) > 2 )
watchout_stud = stud[ watchout_ids_stud ]
watchout_stud
plot( g$fitted.values, stud, ylab = "Studentized Residuals", main = "Studentized Residuals", pch = 16 )
points( g$fitted.values[watchout_ids_stud],
stud[watchout_ids_stud], col = 'pink', pch = 16 )
points( g$fitted.values[watchout_ids_lev],
stud[watchout_ids_lev], col = 'orange', pch = 16 )
abline( h = c(-2,2), lty = 2, col = 'orange' )
legend('topright', col = c('pink','orange'),
c('Studentized Residual', 'Leverages'), pch = rep( 16, 3 ), bty = 'n' )
Cdist = cooks.distance( g )
watchout_ids_Cdist = which( Cdist > 4/(n-p) )
watchout_Cdist = Cdist[ watchout_ids_Cdist ]
watchout_Cdist
#Three suspect points are detected.
par( mfrow = c( 1, 3 ) )
plot( g$fitted.values, Cdist, pch = 16, xlab = 'Fitted values',
ylab = 'Cooks Distance', main = 'Cooks Distance' )
points( g$fitted.values[ watchout_ids_Cdist ], Cdist[ watchout_ids_Cdist ],
col = 'green', pch = 16 )
plot( g$fitted.values, stud, pch = 16, xlab = 'Fitted values',
ylab = 'Studentized Residuals', main = 'Studentized Residuals' )
points( g$fitted.values[ watchout_ids_stud ], stud[ watchout_ids_stud ],
col = 'pink', pch = 16 )
plot( g$fitted.values, lev, pch = 16, xlab = 'Fitted values',
ylab = 'Leverages', main = 'Leverages' )
points( g$fitted.values[ watchout_ids_lev ], lev[ watchout_ids_lev ],
col = 'orange', pch = 16 )
#id_to_keep = (1:n)[ - watchout_ids_Cdist ]
id_to_keep = !( 1:n %in% watchout_ids_Cdist )
gl = lm( sr ~ pop15 + pop75 + dpi + ddpi, savings[ id_to_keep, ]  )
summary( gl )
abs( ( gl$coef - g$coef )/g$coef )
x11()
influencePlot( g, id.method = "identify", main = "influential Plot",
sub = "Circle size is proportial to Cook's Distance" )
library(corrplot)
x11()
influencePlot( g, id.method = "identify", main = "influential Plot",
sub = "Circle size is proportial to Cook's Distance" )
library(BAS)
x11()
influencePlot( g, id.method = "identify", main = "influential Plot",
sub = "Circle size is proportial to Cook's Distance" )
plot(g, which = 5)
plot(g, which = 5)
plot(g, which = 5)
plot(g, which = 5)
x11()
plot(g, which = 5)
influence.measures( g )
d <- lm(sr ~ pop75 + dpi + ddpi,savings)$res
m <- lm(pop15 ~ pop75 + dpi + ddpi,savings)$res
plot(m,d,xlab="pop15 residuals",ylab="Saving residuals", main="Partial Regression")
x11()
plot(m,d,xlab="pop15 residuals",ylab="Saving residuals", main="Partial Regression")
abline(0,g$coef['pop15'])
#Compare the slope on the plot to the original regression and show the line on the plot.
lm(d ~ m)$coef
g$coef
prplot(g,1) # 1 stands for the position of the independent variable
vif( g )
prplot(g,1)
x11()
prplot(g,1)
library(BAS)
data(bodyfat) # help(bodyfat)
View(bodyfat)
# summary(bodyfat)
mod = lm(Weight ~ Abdomen, data = bodyfat)
summary(mod)
mod_res = mod$residuals/summary(mod)$sigma
plot( mod$fitted, mod_res, xlab = 'Fitted values',  ylab = 'Standarzized residuals'  )
x11()
plot( mod$fitted, mod_res, xlab = 'Fitted values',  ylab = 'Standarzized residuals'  )
qqnorm( mod$residuals )
qqline( mod$residuals, col = 'blue' )
x11()
qqnorm( mod$residuals )
qqline( mod$residuals, col = 'blue' )
# abline( 0, 1, col = 'red' )
shapiro.test( mod_res )
#The best lambda that is chosen is the one maximizing the likelihood of the transformed data of being
b = boxcox(Weight ~ Abdomen, data = bodyfat)
names(b)
library(MASS)
library( GGally)
library(BAS)
library(rgl)
library(corrplot)
#The best lambda that is chosen is the one maximizing the likelihood of the transformed data of being
b = boxcox(Weight ~ Abdomen, data = bodyfat)
#The best lambda that is chosen is the one maximizing the likelihood of the transformed data of being
b = boxcox(Weight ~ Abdomen, data = bodyfat)
#The best lambda that is chosen is the one maximizing the likelihood of the transformed data of being
b = boxcox(Weight ~ Abdomen, data = bodyfat)
x11()
b = boxcox(Weight ~ Abdomen, data = bodyfat)
names(b)
best_lambda_ind = which.max( b$y )
best_lambda = b$x[ best_lambda_ind ]
best_lambda
#Finally, we test the new model and we investigate the standardized residuals.
mod1 = lm( (Weight ^ best_lambda - 1)/best_lambda ~ Abdomen, data = bodyfat )
summary(mod1)
mod1_res = mod1$residuals/summary( mod1 )$sigma
plot( mod1$fitted, mod1_res, xlab = 'Fitted values',  ylab = 'Standarzized residuals'  )
x11()
plot( mod1$fitted, mod1_res, xlab = 'Fitted values',  ylab = 'Standarzized residuals'  )
qqnorm( mod1_res )
abline( 0, 1, col = 'red' )
shapiro.test( residuals( mod1 ) )
x11()
qqnorm( mod1_res )
abline( 0, 1, col = 'red' )
data( state )
data( state )
statedata = data.frame( state.x77, row.names = state.abb, check.names = T )
head( statedata )
g = lm( Life.Exp ~ ., data = statedata )
summary( g )
# remove Area
g1 = update( g, . ~ . - Area )
summary( g1 )
# remove Illiteracy
g2 = update( g1, . ~ . - Illiteracy )
summary( g2 )
# Remove Income
g3 = update( g2, . ~ . - Income )
summary( g3 )
# remove Population
g4 = update( g3, . ~ . - Population )
summary( g4 )
cars
x11()
plot(cars, xlab='Speed', ylab='Stopping distance', las=1)
n          <- dim(cars)[[1]]
distance   <- cars$dist
speed1     <- cars$speed
speed2     <- cars$speed^2
### Model:
### distance = beta_0 + beta_1 * speed + beta_2 * speed^2 + Eps
### (linear in the parameters!)
fm <- lm(distance ~ speed1 + speed2)
summary(fm)
# Variance inflation factor
help(vif)
vif(fm)
library(MASS)
library(car)
library(rgl)
library(glmnet)
vif(fm)
# recall vif formula:
1/(1- summary(lm(speed1 ~ speed2))$r.squared )
1/(1- summary(lm(speed2 ~ speed1))$r.squared )
osp.mil.t=heartf_osp[which(heartf_osp$ASL_RESIDENZA=='308'),]
blabla={}
for(i in 1:20){ #583231
if(osp.mil.t$COD_REG[i]==osp.mil.t$COD_REG[i+1]){
gabriolo=unlist(c(osp.mil.t[i,c(3,6,9,10,11,12)]))
timeout=as.integer(osp.mil.t$data_prest[i+1]-(osp.mil.t$data_prest[i]))#+osp.mil.t$qt_prest_Sum[i]))
comohad=osp.mil.t[i,13:36]
comonew=osp.mil.t[i+1,13:36]-osp.mil.t[i,13:36]
countC=0
countB=0
presCOD=heartf_pres[which(heartf_pres$COD_REG==osp.mil.t$COD_REG[i]),c(7,9,10)]   #data,tipo,durata
n=dim(presCOD)[1]
check=0
for(j in 1:n & check==0){
if(presCOD[j,1]>osp.mil.t$data_prest[i] & presCOD[j,1]<osp.mil.t$data_prest[i+1]){
if(startsWith(presCOD[j,2], C, trim=FALSE, ignore.case=TRUE))
countC++
if(startsWith(presCOD[j,2], B, trim=FALSE, ignore.case=TRUE))
countB++
if(presCOD[j,1]>osp.mil.t$data_prest[i+1])
check=1
}
allthi=c(osp.mil.t[i,1],timeout,gabriolo,comohad,comonew,countC,countB)
blabla=rbind(blabla,allthi)
}
}
}
unlist(gabriolo)
install.packages("bakeoff")
library(tidyverse)
library(bakeoff)
plot_off1 <- bakeoff::ratings %>%
mutate(ep_id = row_number()) %>%
select(ep_id, viewers_7day, series, episode)
# create coordinates for labels
series_labels <- plot_off1 %>%
group_by(series) %>%
summarize(y_position = median(viewers_7day) + 1,
x_position = mean(ep_id))
# make the plot
ggplot(plot_off1, aes(x = ep_id, y = viewers_7day, fill = factor(series))) +
geom_col(alpha = .9) +
ggtitle("Series 8 was a Big Setback in Viewers",
subtitle= "7-Day Viewers across All Series/Episodes") +
geom_text(data = series_labels, aes(label = series,
x = x_position,
y = y_position)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.title.x = element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank()) +
scale_fill_bakeoff(guide = "none")
tuesdata <- tidytuesdayR::tt_load('2022-10-25')
tuesdata <- tidytuesdayR::tt_load(2022, week = 43)
bakers <- tuesdata$bakers
# Or read in the data manually
bakers <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-10-25/bakers.csv')
View(bakers)
Sys.which("make")
install.packages("jsonlite", type = "source")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
library(devtools)
.libPaths()
install.packages("usethis")
library(devtools)
install.packages("devtools")
install.packages("devtools")
install.packages("cli")
install.packages("cli")
# Remove Package
remove.packages("cli")
detach('cli')
detach(cli)
detach(package:cli,unload=TRUE)
detach(package:'cli',unload=TRUE)
detach("package:cli",unload=TRUE)
detach_package <- function(pkg, character.only = FALSE)
{
if(!character.only)
{
pkg <- deparse(substitute(pkg))
}
search_item <- paste("package", pkg, sep = ":")
while(search_item %in% search())
{
detach(search_item, unload = TRUE, character.only = TRUE)
}
}
detach_package(cli)
install.packages("cli")
install.packages("devtools")
library(devtools)
install_github(repo="ryantibs/conformal", subdir="conformalInference")
#devtools::install_github(repo="ryantibs/conformal", subdir="conformalInference")
library(conformalInference)
gen <- read.table('01-2023.csv', header=T,sep = ';')
setwd("C:/Users/User/Desktop/ASP/Oasis/oasis-project/madrid/csv_files")
gen <- read.table('01-2023.csv', header=T,sep = ';')
gen.head()
head(gen)
head(gen[,c(1,4)])
genred <- aggregate(gen[,c(1,4)],by=list(id=id),mean)
genred <- aggregate(gen[,c(1,4)],by=list(id),mean)
genred <- aggregate(gen[,c(1,4)],by=list(id=id),mean)
genx <- as.data.frame(gen[,c(1,4)])
genred <- aggregate(genx,by=list(id=id),mean)
View(genx)
genred <- aggregate(genx,by=list(genx$id),mean)
head(genred)
genred <- aggregate(genx$intensidad,by=list(id=genx$id),mean)
head(genred)
write.csv(genred, file='genred.csv')
#gen <- read.table('01-2023.csv', header=T,sep = ';')
feb <- read.table('02-2023.csv', header=T,sep = ';')
head(feb[,c(1,4)])
febx <- as.data.frame(feb[,c(1,4)])
febred <- aggregate(febx$intensidad,by=list(id=febx$id),mean)
head(febred)
write.csv(febred, file='febred.csv')
rm(list=ls())
mar <- read.table('03-2022.csv', header=T,sep = ';')
head(mar[,c(1,4)])
marx <- as.data.frame(mar[,c(1,4)])
marred <- aggregate(marx$intensidad,by=list(id=marx$id),mean)
head(marred)
write.csv(marred, file='marred.csv')
rm(list=ls())
apr <- read.table('04-2022.csv', header=T,sep = ';')
head(apr[,c(1,4)])
aprx <- as.data.frame(apr[,c(1,4)])
aprred <- aggregate(aprx$intensidad,by=list(id=aprx$id),mean)
head(aprred)
write.csv(aprred, file='aprred.csv')
rm(list=ls())
mag <- read.table('05-2022.csv', header=T,sep = ';')
head(mag[,c(1,4)])
magx <- as.data.frame(mag[,c(1,4)])
magred <- aggregate(magx$intensidad,by=list(id=magx$id),mean)
head(magred)
write.csv(magred, file='magred.csv')
giu <- read.table('06-2022.csv', header=T,sep = ';')
head(giu[,c(1,4)])
giux <- as.data.frame(giu[,c(1,4)])
giured <- aggregate(giux$intensidad,by=list(id=giux$id),mean)
head(giured)
write.csv(giured, file='giured.csv')
rm(list=ls())
lug <- read.table('07-2022.csv', header=T,sep = ';')
head(lug[,c(1,4)])
lugx <- as.data.frame(lug[,c(1,4)])
lugred <- aggregate(lugx$intensidad,by=list(id=lugx$id),mean)
head(lugred)
write.csv(lugred, file='lugred.csv')
rm(list=ls())
ago <- read.table('08-2022.csv', header=T,sep = ';')
head(ago[,c(1,4)])
agox <- as.data.frame(ago[,c(1,4)])
agored <- aggregate(agox$intensidad,by=list(id=agox$id),mean)
head(agored)
write.csv(agored, file='agored.csv')
rm(list=ls())
set <- read.table('09-2022.csv', header=T,sep = ';')
head(set[,c(1,4)])
setx <- as.data.frame(set[,c(1,4)])
setred <- aggregate(setx$intensidad,by=list(id=setx$id),mean)
head(setred)
write.csv(setred, file='setred.csv')
rm(list=ls())
ott <- read.table('10-2022.csv', header=T,sep = ';')
head(ott[,c(1,4)])
ottx <- as.data.frame(ott[,c(1,4)])
ottred <- aggregate(ottx$intensidad,by=list(id=ottx$id),mean)
head(ottred)
write.csv(ottred, file='ottred.csv')
rm(list=ls())
nov <- read.table('11-2022.csv', header=T,sep = ';')
head(nov[,c(1,4)])
novx <- as.data.frame(nov[,c(1,4)])
novred <- aggregate(novx$intensidad,by=list(id=novx$id),mean)
head(novred)
write.csv(novred, file='novred.csv')
rm(list=ls())
dic <- read.table('12-2022.csv', header=T,sep = ';')
head(dic[,c(1,4)])
dicx <- as.data.frame(dic[,c(1,4)])
dicred <- aggregate(dicx$intensidad,by=list(id=dicx$id),mean)
head(dicred)
write.csv(dicred, file='dicred.csv')
rm(list=ls())
gen <- read.table('genred.csv', header=T)
View(gen)
gen <- read.table('genred.csv', header=T,sep = ';')
View(gen)
gen <- read.csv('genred.csv')
View(gen)
gen <- read.csv('genred.csv')
feb <- read.csv('febred.csv')
mar <- read.csv('marred.csv')
apr <- read.csv('aprred.csv')
mag <- read.csv('magred.csv')
giu <- read.csv('giured.csv')
lug <- read.csv('lugred.csv')
ago <- read.csv('agored.csv')
set <- read.csv('setred.csv')
ott <- read.csv('ottred.csv')
nov <- read.csv('novred.csv')
dic <- read.csv('dicred.csv')
tot <- rbind(gen,feb,mar,apr,mag,giu,lug,ago,set,ott,nov,dic)
View(tot)
totred <- aggregate(tot$x,by=list(id=tot$id),mean)
head(totred)
write.csv(totred, file='totred.csv')
rm(list=ls())
totred <- read.csv('totred.csv')
coord <- read.csv('point ubication.csv')
View(coord)
coord <- read.table('point ubication.csv', header=T,sep = ';')
head(coord)
head(coord)
head(totred)
df <- merge(totred, coord[c("id", "utm_x")],  by = c("id"))
head(df)
df <- merge(totred, coord[c("id", "utm_x", "utm_y", "longitud", "latitud")],  by = c("id"))
head(df)
write.csv(df, file='traffic_points.csv')
