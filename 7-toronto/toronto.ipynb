{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "import seaborn as sns\n",
    "import shapefile as shp\n",
    "import pyproj\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import LineString\n",
    "from shapely.geometry import box\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import mapclassify as mc\n",
    "from scipy.spatial import distance\n",
    "from scipy import ndimage\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "import csv\n",
    "import os\n",
    "import importlib\n",
    "from pulp import *\n",
    "import math\n",
    "import scripts.neighbors as neigh #scripts.\n",
    "importlib.reload(neigh)\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_width = 320\n",
    "pd.set_option('display.width', desired_width)\n",
    "np.set_printoptions(linewidth=desired_width)\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate traffic data\n",
    "city='toronto'\n",
    "data_path = os.getcwd()+'\\\\csv_files\\\\'+city+'_traffic_points.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "raw_traffic_df = pd.DataFrame(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        detid      interval        flow       occ  error  ...       pos  lanes  linkid       long        lat\n",
      "0    N20111G1  42707.230769  459.888547  0.083891    1.0  ...  0.204658    1.0    95.0 -79.397389  43.676565\n",
      "1    N20111G2  42790.320370   79.056022  0.016396    1.0  ...  0.203545    1.0    94.0 -79.397429  43.676557\n",
      "2    N20111J1  42707.230769  323.588034  0.092443    1.0  ...  0.241932    1.0   123.0 -79.395643  43.672516\n",
      "3    N20111J2  42707.230769  286.815385  0.048186    1.0  ...  0.243551    1.0   124.0 -79.395683  43.672505\n",
      "4    N20111K1  42721.553463  430.078682  0.089092    NaN  ...  0.073968    1.0   122.0 -79.396561  43.671633\n",
      "..        ...           ...         ...       ...    ...  ...       ...    ...     ...        ...        ...\n",
      "183  N31211G1  42764.605398  148.032456  0.094139    1.0  ...  0.075322    1.0    94.0 -79.366566  43.647363\n",
      "184  N31211K1  42764.605398  178.729416  0.024838    1.0  ...  0.231115    1.0    88.0 -79.368973  43.645681\n",
      "185  N31211K2  42764.605398  198.383328  0.026666    1.0  ...  0.229745    1.0    87.0 -79.368993  43.645716\n",
      "186  N31221D1  42764.605398  168.940895  0.031265    1.0  ...  0.380990    1.0    93.0 -79.365804  43.646362\n",
      "187  N31221D2  42764.605398  100.693543  0.013216    1.0  ...  0.377158    1.0    92.0 -79.365826  43.646404\n",
      "\n",
      "[188 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_traffic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load poi\n",
    "gp_poi=shp.Reader(os.getcwd()+'\\shapefiles\\gis_osm_pois_free_1.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_df_to_gdf(df):\n",
    "    \"\"\"takes a dataframe with columns named 'longitude' and 'latitude'\n",
    "    to transform to a geodataframe with point features\"\"\"\n",
    "\n",
    "    df['coordinates'] = df[['long', 'lat']].values.tolist()\n",
    "    df['coordinates'] = df['coordinates'].apply(Point)\n",
    "    df = gpd.GeoDataFrame(df, geometry='coordinates')\n",
    "    return df\n",
    "    \n",
    "def polygon_df_to_gdf(df):\n",
    "    \"\"\"takes a dataframe with columns named 'longitude' and 'latitude'\n",
    "    to transform to a geodataframe with point features\"\"\"\n",
    "    geometry = [box(x1, y1, x2, y2) for x1,y1,x2,y2 in zip(df.left, df.bottom, df.right, df.top)]\n",
    "    df = df.drop(['left', 'bottom', 'right', 'top'], axis=1)\n",
    "    geodf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "    return df\n",
    "\n",
    "def read_shapefile(sf):\n",
    "    \"\"\"\n",
    "    Read a shapefile into a Pandas dataframe with a 'coords'\n",
    "    column holding the geometry information. This uses the pyshp\n",
    "    package\n",
    "    \"\"\"\n",
    "    fields = [x[0] for x in sf.fields][1:]\n",
    "    records = sf.records()\n",
    "    records = [y[:] for y in sf.records()]\n",
    "    shps = [s.points for s in sf.shapes()]\n",
    "    df = pd.DataFrame(columns=fields, data=records)\n",
    "    df = df.assign(coords=shps)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_points_gdf = point_df_to_gdf(raw_traffic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_832\\1920669170.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  traffic_points_gdf.to_file(os.getcwd()+'\\\\shapefiles\\\\traffic_points.shp')\n"
     ]
    }
   ],
   "source": [
    "traffic_points_gdf.to_file(os.getcwd()+'\\\\shapefiles\\\\traffic_points.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_charg_stat = shp.Reader(os.getcwd()+'\\\\shapefiles\\\\EV_points.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 3: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ASP\\Oasis\\oasis-project\\7-toronto\\toronto.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m shp_path_roads_1 \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd()\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mshapefiles\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmap.shp\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sf_roads_1 \u001b[39m=\u001b[39m shp\u001b[39m.\u001b[39mReader(shp_path_roads_1)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_roads \u001b[39m=\u001b[39m read_shapefile(sf_roads_1)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_roads[\u001b[39m'\u001b[39m\u001b[39mcoords\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_roads[\u001b[39m'\u001b[39m\u001b[39mcoords\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(LineString)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m gdf_roads \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mGeoDataFrame(df_roads, geometry\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoords\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ASP\\Oasis\\oasis-project\\7-toronto\\toronto.ipynb Cell 10\u001b[0m in \u001b[0;36mread_shapefile\u001b[1;34m(sf)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mRead a shapefile into a Pandas dataframe with a 'coords'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mcolumn holding the geometry information. This uses the pyshp\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mpackage\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m fields \u001b[39m=\u001b[39m [x[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m sf\u001b[39m.\u001b[39mfields][\u001b[39m1\u001b[39m:]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m records \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mrecords()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m records \u001b[39m=\u001b[39m [y[:] \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m sf\u001b[39m.\u001b[39mrecords()]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ASP/Oasis/oasis-project/7-toronto/toronto.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m shps \u001b[39m=\u001b[39m [s\u001b[39m.\u001b[39mpoints \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m sf\u001b[39m.\u001b[39mshapes()]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shapefile.py:1716\u001b[0m, in \u001b[0;36mReader.records\u001b[1;34m(self, fields)\u001b[0m\n\u001b[0;32m   1714\u001b[0m fieldTuples,recLookup,recStruct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__recordFields(fields)\n\u001b[0;32m   1715\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumRecords):\n\u001b[1;32m-> 1716\u001b[0m     r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__record(oid\u001b[39m=\u001b[39;49mi, fieldTuples\u001b[39m=\u001b[39;49mfieldTuples, recLookup\u001b[39m=\u001b[39;49mrecLookup, recStruct\u001b[39m=\u001b[39;49mrecStruct)\n\u001b[0;32m   1717\u001b[0m     \u001b[39mif\u001b[39;00m r:\n\u001b[0;32m   1718\u001b[0m         records\u001b[39m.\u001b[39mappend(r)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shapefile.py:1683\u001b[0m, in \u001b[0;36mReader.__record\u001b[1;34m(self, fieldTuples, recLookup, recStruct, oid)\u001b[0m\n\u001b[0;32m   1680\u001b[0m             value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m# unknown value is set to missing\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1682\u001b[0m     \u001b[39m# anything else is forced to string/unicode\u001b[39;00m\n\u001b[1;32m-> 1683\u001b[0m     value \u001b[39m=\u001b[39m u(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencodingErrors)\n\u001b[0;32m   1684\u001b[0m     value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mrstrip(\u001b[39m'\u001b[39m\u001b[39m\\x00\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39m# remove null-padding at end of strings\u001b[39;00m\n\u001b[0;32m   1685\u001b[0m record\u001b[39m.\u001b[39mappend(value)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shapefile.py:120\u001b[0m, in \u001b[0;36mu\u001b[1;34m(v, encoding, encodingErrors)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mu\u001b[39m(v, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m, encodingErrors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m    119\u001b[0m         \u001b[39m# For python 3 decode bytes to str.\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m v\u001b[39m.\u001b[39;49mdecode(encoding, encodingErrors)\n\u001b[0;32m    121\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    122\u001b[0m         \u001b[39m# Already str.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m         \u001b[39mreturn\u001b[39;00m v\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 3: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "#shp_path_roads_1 = os.getcwd()+'\\\\shapefiles\\\\gis_osm_roads_free_1.shp'\n",
    "shp_path_roads_1 = os.getcwd()+'\\\\shapefiles\\\\map.shp'\n",
    "sf_roads_1 = shp.Reader(shp_path_roads_1)\n",
    "df_roads = read_shapefile(sf_roads_1)\n",
    "df_roads['coords'] = df_roads['coords'].apply(LineString)\n",
    "gdf_roads = gpd.GeoDataFrame(df_roads, geometry='coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_charg_stat = read_shapefile(shp_charg_stat)\n",
    "df_charg_stat['long']=[df_charg_stat['coords'][i][0][0] for i in range(len(df_charg_stat))]\n",
    "df_charg_stat['lat']=[df_charg_stat['coords'][i][0][1] for i in range(len(df_charg_stat))]\n",
    "drop_columns = ['coords']\n",
    "df_charg_stat = df_charg_stat.drop(labels=drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_chargers_gdf = point_df_to_gdf(df_charg_stat)\n",
    "existing_chargers_gdf.to_file(os.getcwd()+'\\\\shapefiles\\\\existing_chargers.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert poi\n",
    "poi_df = read_shapefile(gp_poi)\n",
    "poi_df['long']=[poi_df['coords'][i][0][0] for i in range(len(poi_df))]\n",
    "poi_df['lat']=[poi_df['coords'][i][0][1] for i in range(len(poi_df))]\n",
    "poi_gdf = point_df_to_gdf(poi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_traffic_df['long'].max())\n",
    "print(raw_traffic_df['long'].min())\n",
    "print(raw_traffic_df['lat'].max())\n",
    "print(raw_traffic_df['lat'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_traffic_df['long'].nlargest(2).iloc[-1])\n",
    "print(raw_traffic_df['long'].nsmallest(2).iloc[-1])\n",
    "print(raw_traffic_df['lat'].nlargest(2).iloc[-1])\n",
    "print(raw_traffic_df['lat'].nsmallest(2).iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lim = (43.63,43.68)                                    # y coordinates \n",
    "x_lim = (-79.36,-79.42)                                    # x coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect=Polygon([(x_lim[0],y_lim[0]),(x_lim[0],y_lim[1]),(x_lim[1],y_lim[1]),(x_lim[1],y_lim[0]),(x_lim[0],y_lim[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_points_clip=traffic_points_gdf.clip(rect)\n",
    "traffic_points_clip.to_file(os.getcwd()+'\\\\shapefiles\\\\traffic_points_clip.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_gdf = poi_gdf.clip(rect)\n",
    "#poi_gdf.to_file(os.getcwd()+'\\\\shapefiles\\\\poi_clip.shp')   #errore??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_roads_clip=gdf_roads.clip(rect)\n",
    "#drop_columns = ['coords']\n",
    "#gdf_roads_clip = gdf_roads_clip.drop(labels=drop_columns, axis=1)\n",
    "gdf_roads_clip.to_file(os.getcwd()+'\\\\shapefiles\\\\map.shp')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gdf_roads_clip.plot(figsize=(12, 8), color='deepskyblue', lw=0.4, zorder=0)  # Zorder controls the layering of the charts with\n",
    "base.set_xlim(x_lim)\n",
    "base.set_ylim(y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gdf_roads_clip.plot(figsize=(12, 8), color='grey', lw=0.4, zorder=0)  # Zorder controls the layering of the charts with\n",
    "base.set_xlim(x_lim)\n",
    "base.set_ylim(y_lim)\n",
    "traffic_points_clip.plot(ax=base,column='flow',legend=True)#, cmap='cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(poi_gdf['fclass'].unique())     #106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_poi = pd.DataFrame(poi_gdf['fclass'].value_counts())\n",
    "print(count_poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gdf_roads_clip.plot(figsize=(12, 8), color='grey', lw=0.4, zorder=0)  # Zorder controls the layering of the charts with\n",
    "base.set_xlim(x_lim)\n",
    "base.set_ylim(y_lim)\n",
    "poi_gdf.plot(ax=base,markersize=3,column='fclass',legend=True) #,color='red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gdf_roads_clip.plot(figsize=(12, 8), color='grey', lw=0.4, zorder=0)  # Zorder controls the layering of the charts with\n",
    "base.set_xlim(x_lim)\n",
    "base.set_ylim(y_lim)\n",
    "existing_chargers_gdf.plot(ax=base,color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exagon(r,y_lim,x_lim):\n",
    "    xmin =x_lim[0]\n",
    "    xmax =x_lim[1]\n",
    "    ymin =y_lim[0]\n",
    "    ymax =y_lim[1]\n",
    "\n",
    "    # twice the height of a hexagon's equilateral triangle\n",
    "    h = (r * math.sqrt(3))\n",
    "\n",
    "    polygons = []\n",
    "    tot_traffic_pre=[]\n",
    "    tot_mixed=[]\n",
    "    tot_chargers=[]\n",
    "    tot_centroide_x=[]\n",
    "    tot_centroide_y=[]\n",
    "    colore=[]\n",
    "    rows=0\n",
    "    cols=0\n",
    "    # create the hexagons\n",
    "    for x in np.arange(xmin, xmax, h):\n",
    "        k=1\n",
    "        for y in np.arange(ymin, ymax, (h * h / r / 2)):\n",
    "            if k==0:\n",
    "                x=x+r * math.sqrt(3)/2\n",
    "                hexagon = shape(\n",
    "                    {\n",
    "                        \"type\": \"Polygon\",\n",
    "                        \"coordinates\": [\n",
    "                            [\n",
    "                                [x, y + r],\n",
    "                                [x + h / 2, y + r / 2],\n",
    "                                [x + h / 2, y - r / 2],\n",
    "                                [x, y - r],\n",
    "                                [x - h / 2, y - r / 2],\n",
    "                                [x - h / 2, y + r / 2],\n",
    "                                [x, y + r],\n",
    "                            ]\n",
    "                        ],\n",
    "                    }\n",
    "                )\n",
    "                polygons.append(hexagon)\n",
    "                centroide_x=x\n",
    "                centroide_y=y\n",
    "                x=x-r * math.sqrt(3)/2\n",
    "                k=1\n",
    "            elif k==1:\n",
    "                hexagon = shape(\n",
    "                    {\n",
    "                        \"type\": \"Polygon\",\n",
    "                        \"coordinates\": [\n",
    "                            [\n",
    "                                [x, y + r],\n",
    "                                [x + h / 2, y + r / 2],\n",
    "                                [x + h / 2, y - r / 2],\n",
    "                                [x, y - r],\n",
    "                                [x - h / 2, y - r / 2],\n",
    "                                [x - h / 2, y + r / 2],\n",
    "                                [x, y + r],\n",
    "                            ]\n",
    "                        ],\n",
    "                    }\n",
    "                )\n",
    "                polygons.append(hexagon)\n",
    "                k=0\n",
    "                centroide_x=x\n",
    "                centroide_y=y\n",
    "            tot_centroide_x.append(centroide_x)\n",
    "            tot_centroide_y.append(centroide_y)\n",
    "            parziale=traffic_points_gdf.clip(hexagon)[\"flow\"].sum()\n",
    "            tot_traffic_pre.append(parziale)\n",
    "            #mixed=mean_car_count_gdf.clip(hexagon)[\"mixed_use_area_per_cell\"].mean()\n",
    "            #tot_mixed.append(mixed)\n",
    "            chargers=existing_chargers_gdf.clip(hexagon)['long'].count()\n",
    "            tot_chargers.append(chargers)\n",
    "            rows+=1\n",
    "        cols+=1   \n",
    "    rows=int(rows/cols)\n",
    "    tot_traffic = copy.copy(tot_traffic_pre)\n",
    "    for i in range(len(tot_traffic)):\n",
    "        if tot_traffic_pre[i]==0:\n",
    "            v_n = neigh.neighbors(rows,cols,i)[0]\n",
    "            tot_traffic[i] = np.mean([tot_traffic_pre[int(j)] for j in v_n])\n",
    "    \n",
    "    mas=max(tot_traffic)\n",
    "    for k in range(len(tot_traffic)):\n",
    "        if tot_traffic[k]<=0.0*mas:\n",
    "            col='lightcyan'\n",
    "        elif tot_traffic[k]<=0.15*mas:\n",
    "            col='lightskyblue'\n",
    "        elif tot_traffic[k]<=0.4*mas:\n",
    "            col='deepskyblue'\n",
    "        elif tot_traffic[k]<=0.6*mas:\n",
    "            col='royalblue'\n",
    "        elif tot_traffic[k]<=mas:\n",
    "            col='darkblue'\n",
    "        colore.append(col)\n",
    "    with open('dati.csv', mode='w') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        #scriviamo prima la riga di intestazione\n",
    "        csv_writer.writerow(['ID', 'Traffico', 'no_existing_chg', 'centroid_x', 'centroid_y', 'Colore']) #,'mixed_use_area_per_cell'\n",
    "        for k in range(len(tot_chargers)):\n",
    "            csv_writer.writerow([k,tot_traffic[k],tot_chargers[k],tot_centroide_x[k],tot_centroide_y[k],colore[k]]) #,tot_mixed[k]\n",
    "    #poly_grid = gpd.GeoDataFrame({'geometry': polygons}) \n",
    "    #base = gdf_roads_clip.plot(figsize=(12, 8), color='deepskyblue', lw=0.4, zorder=0)  # Zorder controls the layering of the charts with\n",
    "    #base.set_xlim(x_lim)\n",
    "    #base.set_ylim(y_lim)    \n",
    "    #poly_grid.plot(ax=base, facecolor=colore, edgecolor='black', lw=0.5, zorder=15)\n",
    "    #poly_grid.to_file(os.getcwd()+'\\\\shapefiles\\\\grid_exa.shp')\n",
    "    return polygons,rows,cols,colore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exagon grid\n",
    "radius = 0.00004\n",
    "polygons,rows,cols,colore = exagon(radius,y_lim,x_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_grid = gpd.GeoDataFrame({'geometry': polygons}) \n",
    "base = gdf_roads_clip.plot(figsize=(12, 8), color='black', lw=0.4, zorder=0)  # Zorder controls the layering of the charts with\n",
    "base.set_xlim(x_lim)\n",
    "base.set_ylim(y_lim)    \n",
    "poly_grid.plot(ax=base, facecolor=colore, edgecolor='black', lw=0.5, zorder=15,alpha=0.55)\n",
    "#poly_grid.plot(ax=base, facecolor='#999999', edgecolor='black', lw=0.5, zorder=15)\n",
    "poly_grid.to_file(os.getcwd()+'\\\\shapefiles\\\\grid_exa.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_points = gpd.read_file(os.getcwd()+'\\\\shapefiles\\\\traffic_points.shp')\n",
    "polys = gpd.read_file(os.getcwd()+'\\\\shapefiles\\\\grid_exa.shp')\n",
    "points_polys = gpd.sjoin(traffic_points, polys, how=\"right\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GIS data and car park location data\n",
    "GIS_data = pd.read_csv(os.getcwd()+'\\\\dati.csv')\n",
    "GIS_df = pd.DataFrame(GIS_data)\n",
    "#GIS_df['mixed_use_area_per_cell']=GIS_df['mixed_use_area_per_cell'].fillna(0)\n",
    "\n",
    "car_park_data = GIS_df.iloc[:,[0,3,4]]\n",
    "car_park_df = pd.DataFrame(car_park_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sets(df_demand, df_parking):\n",
    "    \"\"\"Generate sets to use in the optimization problem\"\"\"\n",
    "    # set of charging demand locations (destinations)\n",
    "    demand_lc = df_demand.index.tolist()\n",
    "    # set of candidates for charging station locations (currently existing parking lots)\n",
    "    chg_lc = df_parking.index.tolist()\n",
    "    return demand_lc, chg_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_parameters(df_demand, df_parking):\n",
    "    \"\"\"Generate parameters to use in the optimization problem,\n",
    "    including cost to install charging stations, operating costs and others...\"\"\"\n",
    "\n",
    "    v0 = 0.05   # the charging possibility of an EV in cell i\n",
    "    u = 0.10    # the EV penetration rate (utilisation rate) - 10 % of each day are used for charging\n",
    "    pe = 0.17   # price of electricity per kWh (£/kWh)\n",
    "    lj = 10     # maximum number of chargers in a station\n",
    "    alpha = 52  # Average battery capacity (kWh)\n",
    "    N = 10      # Total number of stations to be installed\n",
    "    #r= 150      # \"Radius\" of the exagon\n",
    "    \n",
    "    #Ai = df_demand[\"mixed_use_area_per_cell\"]  # Ai stands for sum of area of the mixed use parts in cell i\n",
    "    #A = math.sqrt(3)*1.5*r*r             # A is the total area of cell i\n",
    "    vi = v0 #Ai / A * v0                           # Where vi is the charging possibility of an EV in cell i\n",
    "    fi = df_demand[\"Traffico\"]          # Where fi is the average traffic flow in grid i\n",
    "    di = u * vi * fi                           # Where di represents the charging demand of EV in grid i\n",
    "    di = di.to_dict()\n",
    "\n",
    "    # Fast Chargers\n",
    "    df_demand['m'] = 2                       # Number of charging sessions per day (session/day)\n",
    "    m = df_demand['m'].to_dict()\n",
    "    df_demand['p'] = 20 #!!!!!!!!!!!!!!!!!                       # Cost of charging per minute (£/minute) (approx £6-7/30min)\n",
    "    p = df_demand['p'].to_dict()\n",
    "    df_demand['t'] = 240                     # Charging time for an EV (minutes)\n",
    "    t = df_demand['t'].to_dict()\n",
    "    df_demand['ci_j'] = 1000                 # Installation cost\n",
    "    ci_j = df_demand['ci_j'].to_dict()\n",
    "    df_demand['cr_j'] = 30                   # cr_j represents the parking fee per day of parking lot j\n",
    "    cr_j = df_demand['cr_j'].to_dict()\n",
    "    df_demand['ce_j'] = 1100                 # ce_j represents the price of a charger in station j\n",
    "    ce_j = df_demand['ce_j'].to_dict()\n",
    "\n",
    "    # distance matrix of charging station location candidates and charging demand location\n",
    "    coords_parking = [(x, y) for x, y in zip(df_parking['centroid_x'], df_parking['centroid_y'])]\n",
    "\n",
    "    coords_demand = [(x, y) for x, y in zip(df_demand['centroid_x'], df_demand['centroid_y'])]\n",
    "\n",
    "    distance_matrix = distance.cdist(coords_parking, coords_demand, 'euclidean')\n",
    "    scaling_ratio = 1\n",
    "    distance_matrix2 = scaling_ratio * distance_matrix\n",
    "    distance_matrix3 = pd.DataFrame(distance_matrix2, index=df_parking.index.tolist(),\n",
    "                                    columns=df_demand.index.tolist())\n",
    "                                    \n",
    "    #poi_df = qge.read_shapefile(gp_poi)\n",
    "    coords_pois = [(x, y) for x, y in zip(poi_df['long'], poi_df['lat'])]\n",
    "    distance_matrix_poi = distance.cdist(coords_parking, coords_pois, 'euclidean')\n",
    "    distance_matrix_poi = pd.DataFrame(distance_matrix_poi, index=df_parking.index.tolist())\n",
    "    distance_poi = distance_matrix_poi.sum()\n",
    "    max = np.max(distance_poi)\n",
    "    min = np.min(distance_poi)\n",
    "    d_poi_scale = (distance_poi - min)/(max - min) \n",
    "    plt.hist(d_poi_scale)\n",
    "    #plt.show()\n",
    "    #print(distance_poi.head())\n",
    "    return di, m, p, t, ci_j, cr_j, ce_j, pe, alpha, lj, N, distance_matrix3, d_poi_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_demand(df_demand):\n",
    "    \"\"\"generate the current demand for charging for each cell i\"\"\"\n",
    "\n",
    "    diz = df_demand[\"no_existing_chg\"]  # Number of existing chargers in cell i\n",
    "    diz = diz.to_dict()\n",
    "\n",
    "    return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(df_demand, df_parking):\n",
    "\n",
    "    # Import i and j set function\n",
    "    demand_lc, chg_lc = gen_sets(df_demand, df_parking)\n",
    "\n",
    "    # Import parameters function\n",
    "    di, m, p, t, ci_j, cr_j, ce_j, pe, alpha, lj, N, distance_matrix, d_poi_scale = gen_parameters(df_demand, df_parking)\n",
    "\n",
    "    # Import current demand of car park z in cell i\n",
    "    diz = gen_demand(df_demand)\n",
    "\n",
    "    # set up the optimization problem\n",
    "    prob = LpProblem('FacilityLocation', LpMaximize)\n",
    "\n",
    "    n = LpVariable.dicts(\"no_of_chgrs_station_j\",\n",
    "                         [j for j in chg_lc],\n",
    "                         0, lj, LpInteger)\n",
    "    q = LpVariable.dicts(\"Remaining_dem_station_j\",\n",
    "                         [j for j in chg_lc],\n",
    "                         0)\n",
    "    c = LpVariable.dicts(\"Tot_costs_station_j\",\n",
    "                         [j for j in chg_lc],\n",
    "                         0)\n",
    "    x = LpVariable.dicts(\"UseLocation\", [j for j in chg_lc], 0, 1, LpBinary)\n",
    "\n",
    "    r = np.full([len(demand_lc), len(chg_lc)], None)\n",
    "\n",
    "    for i in demand_lc:\n",
    "        for j in chg_lc:\n",
    "            if distance_matrix[i][j] <= 500:\n",
    "                r[i][j] = 1\n",
    "            else:\n",
    "                r[i][j] = 0\n",
    "    count = np.count_nonzero(r == 1)\n",
    "    #print(\"The number of potential connections with a distance less than 500m is:\", count)\n",
    "\n",
    "    # Objective function\n",
    "    # The scaled distance from the POI is considered as a multiplication factor\n",
    "    prob += lpSum((p[j] * t[j] * q[j] - c[j])*(1-d_poi_scale[j]) for j in chg_lc)\n",
    "\n",
    "    # Create empty dictionary for the remaining demand in cell i\n",
    "    zip_iterator = zip(demand_lc, [None]*len(demand_lc))\n",
    "    dr = dict(zip_iterator)\n",
    "\n",
    "    # For each cell i subtract the existing number of charging stations from the charging demands in cell i\n",
    "    for i in demand_lc:\n",
    "        for j in chg_lc:\n",
    "            dr[i] = di[i] - diz[i] * m[j]\n",
    "            if dr[i] < 0:       # Can't have negative demand therefore limit minimum demand to zero\n",
    "                dr[i] = 0\n",
    "    \n",
    "    #print(dr)\n",
    "    # Constraints\n",
    "    for j in chg_lc:\n",
    "        prob += c[j] == (cr_j[j] + ce_j[j] + ci_j[j] + 0.1 * ce_j[j] + 0.1 * ci_j[j]) * n[j] + pe * alpha * q[j]  \n",
    "    for j in chg_lc:\n",
    "        prob += q[j] - n[j] * m[j] <= 0                                 # Constraint 1\n",
    "    for j in chg_lc:\n",
    "        prob += q[j] - lpSum(r[i][j] * dr[i] for i in demand_lc) <= 0   # Constraint 2\n",
    "    for i in chg_lc:\n",
    "        prob += lpSum(x[j] * r[i][j] for j in chg_lc) - 1 <= 0          # Constraint 3\n",
    "    for j in chg_lc:\n",
    "        prob += n[j] - x[j] >= 0                                        # Constraint 4\n",
    "    for j in chg_lc:\n",
    "        prob += n[j] - lj * x[j] <= 0                                   # Constraint 5\n",
    "\n",
    "    prob += lpSum(x[j] for j in chg_lc) == N                            # Constraint 6\n",
    "\n",
    "    prob.solve()\n",
    "    print(\"Status: \", LpStatus[prob.status])\n",
    "    tolerance = .00001\n",
    "    opt_location = []\n",
    "    for j in chg_lc:\n",
    "        if x[j].varValue > tolerance:   # If binary value x is positive then the car park has been selected\n",
    "            opt_location.append(j)\n",
    "            print(\"Establish charging station at parking lot\", j)\n",
    "    df_status = pd.DataFrame({\"status\": [LpStatus[prob.status]], \"Tot_no_chargers\": [len(opt_location)]})\n",
    "    print(\"Final Optimisation Status:\\n\", df_status)\n",
    "\n",
    "    varDic = {}\n",
    "    for variable in prob.variables():\n",
    "        var = variable.name\n",
    "        if var[:5] == 'no_of':      # Filter to obtain only the variable 'no_of_chgrs_station_j'\n",
    "            varDic[var] = variable.varValue\n",
    "\n",
    "    for variable in prob.variables():\n",
    "        var = variable.name\n",
    "#         print(var)\n",
    "#         print(variable.varValue)\n",
    "\n",
    "    var_df = pd.DataFrame.from_dict(varDic, orient='index', columns=['value'])\n",
    "    # Sort the results numerically\n",
    "    sorted_df = var_df.index.to_series().str.rsplit('_').str[-1].astype(int).sort_values()\n",
    "    var_df = var_df.reindex(index=sorted_df.index)\n",
    "    var_df.reset_index(inplace=True)\n",
    "\n",
    "    location_df = pd.DataFrame(opt_location, columns=['opt_car_park_id'])\n",
    "#     print(location_df.head())\n",
    "#     print(car_park_df.head())\n",
    "    opt_loc_df = pd.merge(location_df, car_park_df, left_on='opt_car_park_id',  right_index=True, how='left')\n",
    "    opt_loc_df2 = pd.merge(opt_loc_df, var_df, left_on='opt_car_park_id',  right_index=True, how='left')\n",
    "#     opt_loc_df2.to_csv(path_or_buf='optimal_locations.csv')\n",
    "\n",
    "    # Import the road shapefiles\n",
    "    '''''\n",
    "    shp_path_roads_1 = os.getcwd()+'\\\\shapefiles\\\\gis_osm_roads_free_1.shp'\n",
    "    sf_roads_1 = shp.Reader(shp_path_roads_1)\n",
    "    df_roads = read_shapefile(sf_roads_1)\n",
    "    df_roads['coords'] = df_roads['coords'].apply(LineString)\n",
    "    df_roads = gpd.GeoDataFrame(df_roads, geometry='coords')\n",
    "    roads_df = df_roads #accrocco al volo\n",
    "\n",
    "    base = roads_df.plot(figsize=(12, 8), color='grey', lw=0.4, zorder=0)\n",
    "    plot = sns.scatterplot(ax=base, x=opt_loc_df['centroid_x'], y=opt_loc_df['centroid_y'], color='dodgerblue', legend='full')\n",
    "    plot.set_xlim(x_lim[0], x_lim[1])\n",
    "    plot.set_ylim(y_lim[0], y_lim[1])\n",
    "    plot.set_title(f'Optimal locations for {len(opt_location)} chargers')\n",
    "\n",
    "    for line in range(0, opt_loc_df2.shape[0]):\n",
    "        plot.text(opt_loc_df2.centroid_x[line] + 50, opt_loc_df2.centroid_y[line],\n",
    "                  opt_loc_df2.value[line], horizontalalignment='left',\n",
    "                  size='medium', color='black', weight='semibold')\n",
    "                  \n",
    "#    print(opt_loc_df2)\n",
    "    \n",
    "    plt.show()\n",
    "    '''''\n",
    "    \n",
    "    v1tot=[]\n",
    "    v2tot=[]\n",
    "    for i in opt_location:\n",
    "        v=neigh.neighbors(rows,cols,i)\n",
    "        v1tot = v1tot + v[0]\n",
    "        v2tot = v2tot + v[1]\n",
    "\n",
    "    v2tot = [int(x) for x in v2tot] \n",
    "    v1tot = [int(x) for x in v1tot] \n",
    "    opt_location = [int(x) for x in opt_location] \n",
    "    color = pd.DataFrame(['white']*len(df_parking)).transpose()\n",
    "    color[v2tot] = 'yellow'\n",
    "    color[v1tot] = 'orange'\n",
    "    color[opt_location] = 'red'\n",
    "    pol2=[polygons[i] for i in v2tot]\n",
    "    poly_grid2 = gpd.GeoDataFrame({'geometry': pol2})\n",
    "    poly_grid2.to_file(os.getcwd()+'\\\\shapefiles\\\\exa_2.shp')\n",
    "    pol1=[polygons[i] for i in v1tot]\n",
    "    poly_grid1 = gpd.GeoDataFrame({'geometry': pol1})\n",
    "    poly_grid1.to_file(os.getcwd()+'\\\\shapefiles\\\\exa_1.shp')\n",
    "    optpol=[polygons[i] for i in opt_location]\n",
    "    poly_grid_opt = gpd.GeoDataFrame({'geometry': optpol})\n",
    "    poly_grid_opt.to_file(os.getcwd()+'\\\\shapefiles\\\\exa_opt.shp')\n",
    "    \n",
    "    print('Done')\n",
    "    return opt_location, df_status, opt_loc_df, opt_loc_df2, color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sets(GIS_df,car_park_df)\n",
    "gen_parameters(GIS_df,car_park_df)\n",
    "gen_demand(GIS_df)\n",
    "opt_loc, stat, opt_loc_df, opt_loc_df2, color_opt = optimize(GIS_df,car_park_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gdf_roads_clip.plot(figsize=(12, 8), color='grey', lw=0.4, zorder=0)\n",
    "plot = sns.scatterplot(ax=base, x=opt_loc_df['centroid_x'], y=opt_loc_df['centroid_y'], color='mediumblue', legend='full')\n",
    "plot.set_xlim(x_lim[0], x_lim[1])\n",
    "plot.set_ylim(y_lim[0], y_lim[1])\n",
    "plot.set_title(f'Optimal locations for {len(opt_loc)} chargers')\n",
    "\n",
    "for line in range(opt_loc_df2.shape[0]):\n",
    "    plot.text(opt_loc_df2.centroid_x[line], opt_loc_df2.centroid_y[line],\n",
    "                opt_loc_df2.value[line], horizontalalignment='left',\n",
    "                size='medium', color='black', weight='semibold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_opt = (color_opt).values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gdf_roads_clip.plot(figsize=(12, 8), color='black', lw=0.4, zorder=0)  # Zorder controls the layering of the charts with\n",
    "base.set_xlim(x_lim)\n",
    "base.set_ylim(y_lim)    \n",
    "poly_grid.plot(ax=base, facecolor=col_opt, edgecolor='black', lw=0.5, zorder=15,alpha=0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_locations=car_park_df.iloc[opt_loc]\n",
    "print(opt_locations[['centroid_x', 'centroid_y']])\n",
    "\n",
    "def point_df_to_gdf2(df):\n",
    "    \"\"\"takes a dataframe with columns named 'longitude' and 'latitude'\n",
    "    to transform to a geodataframe with point features\"\"\"\n",
    "\n",
    "    df['coordinates'] = df[['centroid_x', 'centroid_y']].values.tolist()\n",
    "    df['coordinates'] = df['coordinates'].apply(Point)\n",
    "    df = gpd.GeoDataFrame(df, geometry='coordinates')\n",
    "    return df\n",
    "    \n",
    "    \n",
    "opt_loc_gdf = point_df_to_gdf2(opt_locations)\n",
    "opt_loc_gdf.to_file(os.getcwd()+'\\\\shapefiles\\\\opt_loc_exa.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
